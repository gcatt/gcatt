#Read in Data
Air_Beijing<-read.csv("Data_International/beijing-air-quality.csv",stringsAsFactors = FALSE)
Air_Berlin<-read.csv("Data_International/berlin,-germany-air-quality.csv",stringsAsFactors = FALSE)
Air_Milano<-read.csv("Data_International/milano-senato, lombardia, italy-air-quality.csv",stringsAsFactors = FALSE)
Air_NY<-read.csv("Data_International/new-york, usa-air-quality.csv",stringsAsFactors = FALSE)
Air_Wuhan<-read.csv("Data_International/wuhan-air-quality.csv",stringsAsFactors = FALSE)
#Calculate overall AQI
head(Air_Beijing)
Air_Beijing$AQI<-apply(Air_Beijing[,2:ncol(Air_Beijing)],1,max)
Air_Berlin$AQI<-apply(Air_Berlin[,2:ncol(Air_Berlin)],1,max)
Air_Milano$AQI<-apply(Air_Milano[,2:(ncol(Air_Milano)-1)],1,max)
Air_NY$AQI<-apply(Air_NY[,2:ncol(Air_NY)],1,max)
Air_Wuhan$AQI<-apply(Air_Wuhan[,2:ncol(Air_Wuhan)],1,max)
#Format as Datum
Air_Beijing$date <- as.Date(Air_Beijing$date , format = "%Y/%m/%d")
Air_Berlin$date <- as.Date(Air_Berlin$date , format = "%Y/%m/%d")
Air_Milano$date <- as.Date(Air_Milano$date , format = "%Y/%m/%d")
Air_NY$date <- as.Date(Air_NY$date , format = "%Y/%m/%d")
Air_Wuhan$date <- as.Date(Air_Wuhan$date , format = "%Y/%m/%d")
#Plots over all Years
ggplot(data = Air_Beijing,
mapping = aes(y = AQI,
x = date
)) +
geom_line(color="darkblue")+
geom_smooth(color="red")+
ggtitle("Air Quality Index Beijing")+
theme_fivethirtyeight()
runApp()
runApp()
setwd("~/Git Repos/gcatt/App/app")
getwd()
head(dist_100km_male)
mobility <- read.csv('Mobility/Distanzkategorien_in_Prozent_pro_Tag.csv', sep = ';')
colnames(mobility)
str(mobility)
mobility$Datum <- as.Date.factor(mobility$Datum, tryFormats = "%d.%m.%Y")
head(mobility)
### 2km-10km Filter
dist_2_10km <- filter(mobility, Beschreibung == "Distanz", Ausprägung == "2 - 10 Kilometer")
### 10km-20km Filter
dist_10_20km <- filter(mobility, Beschreibung == "Distanz", Ausprägung == "10 - 20 Kilometer")
### 20km-50km Filter
dist_20_50km <- filter(mobility, Beschreibung == "Distanz", Ausprägung == "20 - 50 Kilometer")
### 50km-100km Filter
dist_50_100km <- filter(mobility, Beschreibung == "Distanz", Ausprägung == "50 - 100 Kilometer")
### 100km Filter
dist_100km <- filter(mobility, Beschreibung == "Distanz", Ausprägung == "100++ Kilometer")
### select Studying
dist_100km_stud <- select(dist_100km, "In_Ausbildung", "Datum")
dist_100km_empl <- select(dist_100km, "Erwerbstätig", "Datum")
dist_100km_female <-select(dist_100km, "Weiblich", "Datum")
dist_100km_male <-select(dist_100km, "Männlich", "Datum")
dist_100km_gender <- select(dist_100km, "Männlich", "Weiblich", "Datum")
dist_100km_young <-select(dist_100km, "Alter_15.29", "Datum")
dist_100km_middle <-select(dist_100km, "Alter_30.64", "Datum")
dist_100km_old <- select(dist_100km, "Alter_65.79", "Datum")
dist_100km_old
head(dist_100km_stud)
head(dist_100km_male)
runApp()
plot_employed <- ggplot(data = dist_100km_empl, aes(x = Datum, y = Erwerbstätig)) +
geom_point() +
labs(x = "Date",
y = "Ratio",
title = "Employees travelling more than 100km a day")
runApp()
runApp()
plot_gender <- ggplot() +
geom_line(data = dist_100km_male, aes(x = Datum, y = Männlich, color = "red")) +
geom_line(data = dist_100km_female, aes(x = Datum, y = Weiblich, color ="darkgreen")) +
labs(x = "Date",
y = "Ratio",
title = "Gender Comparison of people travelling more than 100km a day")+
scale_color_manual(name = "Legend", values=c('Male', 'Female'))+
theme(legend.position="right")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
BFD5E3
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
plot_employed <- ggplot(data = dist_100km_empl, aes(x = Datum, y = Erwerbstätig), color = white) +
geom_point() +
labs(x = "Date",
y = "Ratio",
title = "Employees travelling more than 100km a day")+
theme(
panel.background = element_rect(fill = 'white', colour = 'white', size = 2, linetype = "solid"),
panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "grey"),# Background of the entire plot
legend.position="right",)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("shinydashboard")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
RecoveredDB<-read_excel("Statista_data/statistic_id1101076_entwicklung-der-weltweiten-anzahl-geheilter-corona-patienten--covid-19--in-2020.xlsx")
colnames(RecoveredDB)<-c("Datum","RecoveredNumber")
RecoveredGraph<-ggplot(data = RecoveredDB,
mapping = aes(y = RecoveredNumber,
x = Datum
)) +
geom_point(color="darkblue")+
ggtitle("Number of Recovered People worldwide")+
ylab("Number of recovered People")+
ylim(0, 200000)+
theme(
panel.background = element_rect(fill = 'white', colour = 'lightgrey', size = 0.5, linetype = "solid"),
panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "lightgrey"),
panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = "lightgrey"),# Background of the entire plot
legend.position="right",)
runApp()
RecoveredDB<-read_excel("Statista_data/statistic_id1101076_entwicklung-der-weltweiten-anzahl-geheilter-corona-patienten--covid-19--in-2020.xlsx")
colnames(RecoveredDB)<-c("Datum","RecoveredNumber")
View(RecoveredDB)
View(RecoveredDB)
RecoveredDB<-RecoveredDB[-c(1,2),]
View(RecoveredDB)
View(RecoveredDB)
runApp()
RecoveredDB<-read_excel("Statista_data/statistic_id1101076_entwicklung-der-weltweiten-anzahl-geheilter-corona-patienten--covid-19--in-2020.xlsx")
colnames(RecoveredDB)<-c("Datum","RecoveredNumber")
RecoveredDB<-RecoveredDB[-c(1,2),]
RecoveredDB$Datum <- seq(as.Date("2020-01-21"), as.Date("2020-03-28"), by="days")
head(RecoveredDB)
head(RecoveredDB)
RecoveredDB$Datum <- as.Date(RecoveredDB$Datum, '%d. %b')
head(RecoveredDB)
RecoveredGraph<-ggplot(data = RecoveredDB,
mapping = aes(y = RecoveredNumber,
x = Datum
)) +
geom_point(color="darkblue")+
ggtitle("Number of Recovered People worldwide")+
ylab("Number of recovered People")+
ylim(0, 200000)+
theme(
panel.background = element_rect(fill = 'white', colour = 'lightgrey', size = 0.5, linetype = "solid"),
panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "lightgrey"),
panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = "lightgrey"),# Background of the entire plot
legend.position="right",)
runApp()
runApp()
runApp()
runApp()
zue <- read.csv('NABEL_Crawler/Outputs/ZUE.csv', sep = ";")
colnames(zue)
zue <- zue[complete.cases(zue),]
zue$Datum.Zeit <- as.Date(zue$Datum.Zeit, format = "%d.%m.%Y")
#TS of PM10
ts_pm10 <- ts(data=zue$PM10..ug.m3., start = 2010, end=2020, frequency = 24)
ts_pm10
decomp<-decompose(ts_pm10)
plot(decomp, xlab="Year")
plot(decomp, xlab="Year")
plot(decomp, xlab="Year")
decomp<-decompose(ts_co..mg.m3)
setwd("~/Git Repos/gcatt/NABEL_Crawler")
zue <- read.csv('NABEL_Crawler/Outputs/ZUE.csv', sep = ";")
zue <- read.csv('Outputs/ZUE.csv', sep = ";")
colnames(zue)
zue <- zue[complete.cases(zue),]
zue$Datum.Zeit <- as.Date(zue$Datum.Zeit, format = "%d.%m.%Y")
#TS of PM10
ts_pm10 <- ts(data=zue$PM10..ug.m3., start = 2010, end=2020, frequency = 24)
ts_pm10
decomp<-decompose(ts_pm10)
plot(decomp, xlab="Year")
##TS of CO..mg.m3
ts_co..mg.m3 <- ts(data=zue$CO..mg.m3., start = 2015, end=2020, frequency = 24)
ts_co..mg.m3
decomp<-decompose(ts_co..mg.m3)
plot(decomp, xlab="Year")
library(dplyr)
library(ggplot2)
zue <- read.csv('Outputs/ZUE.csv', sep = ";")
colnames(zue)
zue <- zue[complete.cases(zue),]
zue$Datum.Zeit <- as.Date(zue$Datum.Zeit, format = "%d.%m.%Y")
#TS of PM10
ts_pm10 <- ts(data=zue$PM10..ug.m3., start = 2010, end=2020, frequency = 24)
ts_pm10
decomp<-decompose(ts_pm10)
plot(decomp, xlab="Year")
detach("package:shiny", unload = TRUE)
detach("package:shinydashboard", unload = TRUE)
plot(decomp, xlab="Year")
##TS of CO..mg.m3
ts_co..mg.m3 <- ts(data=zue$CO..mg.m3., start = 2015, end=2020, frequency = 24)
ts_co..mg.m3
decomp<-decompose(ts_co..mg.m3)
plot(decomp, xlab="Year")
##TS of NOX
ts_nox <- ts(data = zue$NOX..ug.m3.eq..NO2., start = 2016, end = 2020, frequency = 48)
ts_nox
decomp <- decompose(ts_nox)
plot(decomp, xlab ="Year")
data <- data.frame(
day = zue$Datum.Zeit,
nox = zue$NOX..ug.m3.eq..NO2.
)
ts_ggplot_nox <- ggplot(data, aes(x = day, y=nox))+
geom_line() +
scale_x_date(limit=c(as.Date("2017-01-01"),as.Date("2020-02-11"))) +
xlab("")
ts_ggplot_nox
#NOX
ggplot_nox <- ggplot(data =zue, aes(x = Datum.Zeit, y=NOX..ug.m3.eq..NO2., group = 1)) +
geom_line() +
labs(x ="Date",
y = "NOX",
title ="NOX Data")
ts_ggplot_nox
setwd("~/Git Repos/gcatt/NABEL_Crawler")
zue <- read.csv('Outputs/ZUE.csv', sep = ";")
colnames(zue)
zue <- zue[complete.cases(zue),]
zue$Datum.Zeit <- as.Date(zue$Datum.Zeit, format = "%d.%m.%Y")
#TS of PM10
ts_pm10 <- ts(data=zue$PM10..ug.m3., start = 2010, end=2020, frequency = 24)
ts_pm10
decomp<-decompose(ts_pm10)
plot(decomp, xlab="Year")
##TS of CO..mg.m3
ts_co..mg.m3 <- ts(data=zue$CO..mg.m3., start = 2015, end=2020, frequency = 24)
ts_co..mg.m3
decomp<-decompose(ts_co..mg.m3)
plot(decomp, xlab="Year")
##TS of NOX
ts_nox <- ts(data = zue$NOX..ug.m3.eq..NO2., start = 2016, end = 2020, frequency = 48)
ts_nox
decomp <- decompose(ts_nox)
plot(decomp, xlab ="Year")
data <- data.frame(
day = zue$Datum.Zeit,
nox = zue$NOX..ug.m3.eq..NO2.
)
ts_ggplot_nox <- ggplot(data, aes(x = day, y=nox))+
geom_line() +
scale_x_date(limit=c(as.Date("2017-01-01"),as.Date("2020-02-11"))) +
xlab("")
ts_ggplot_nox
ggplot_nox
#NOX
ggplot_nox <- ggplot(data =zue, aes(x = Datum.Zeit, y=NOX..ug.m3.eq..NO2., group = 1)) +
geom_line() +
labs(x ="Date",
y = "NOX",
title ="NOX Data")
library(dplyr)
library(ggplot2)
zue <- read.csv('Outputs/ZUE.csv', sep = ";")
colnames(zue)
zue <- zue[complete.cases(zue),]
zue$Datum.Zeit <- as.Date(zue$Datum.Zeit, format = "%d.%m.%Y")
#TS of PM10
ts_pm10 <- ts(data=zue$PM10..ug.m3., start = 2010, end=2020, frequency = 24)
ts_pm10
decomp<-decompose(ts_pm10)
plot(decomp, xlab="Year")
##TS of CO..mg.m3
ts_co..mg.m3 <- ts(data=zue$CO..mg.m3., start = 2015, end=2020, frequency = 24)
ts_co..mg.m3
decomp<-decompose(ts_co..mg.m3)
plot(decomp, xlab="Year")
##TS of NOX
ts_nox <- ts(data = zue$NOX..ug.m3.eq..NO2., start = 2016, end = 2020, frequency = 48)
ts_nox
decomp <- decompose(ts_nox)
plot(decomp, xlab ="Year")
data <- data.frame(
day = zue$Datum.Zeit,
nox = zue$NOX..ug.m3.eq..NO2.
)
ts_ggplot_nox <- ggplot(data, aes(x = day, y=nox))+
geom_line() +
scale_x_date(limit=c(as.Date("2017-01-01"),as.Date("2020-02-11"))) +
xlab("")
ts_ggplot_nox
#NOX
ggplot_nox <- ggplot(data =zue, aes(x = Datum.Zeit, y=NOX..ug.m3.eq..NO2., group = 1)) +
geom_line() +
labs(x ="Date",
y = "NOX",
title ="NOX Data")
ggplot_nox
#PM10
ggplot_pm10 <- ggplot(data = zue, aes(x = Datum.Zeit, y=PM10..ug.m3., group = 1)) +
geom_line() +
labs(x = "Date",
y = "PM10",
title = "PM10 Data")
ggplot_pm10
#CO..mg.m3
ggplot_com3 <- ggplot(data = zue, aes(x = Datum.Zeit, y=CO..mg.m3., group = 1)) +
geom_smooth() +
labs(x = "Date",
y = "CO mg",
title = "CO mg Data")
ggplot_com3
shiny::runApp('~/Git Repos/gcatt/App/app')
install.packages("tidyverse")
library(readxl)
library(ggplot2)
library(ggthemes)
library(tidyverse)
Lifestyle<-read.csv("C:/Users/MrGaM/Desktop/StatistaPlots/Lifestyle.csv", sep=";")
colnames(Lifestyle)<-c("Change","China","Germany","UK","USA","Value")
Lifestyle<-Lifestyle[-6]
Lifestyleplot<-Lifestyle %>%
gather(key, value, -Change) %>%
ggplot(aes(x=key, y=value, fill=key)) +
geom_col(position = "dodge") +
facet_wrap(~Change)+
scale_fill_manual(values=rep(c("red","gold","darkblue","darkgreen"),2))+
theme_dark()
Lifestyleplot
setwd("~/Git Repos/gcatt/App/app")
setwd("~/Git Repos/gcatt/App/app")
install.packages("tidyverse")
install.packages("tidyverse")
runApp()
install.packages("tidyverse")
shiny::runApp()
runApp()
install.packages("tidyverse")
#install.packages("quantmod")
library(quantmod)
# Downloading Prices via Yahoo Finance API
portfolio_index <- NULL
tickers_index <- c("^GSPC", "AGG") # Tickers from Yahoo Finance for S&P 500 (^GSPC) and US Aggregate Bond Index (AGG)
for (Ticker in tickers_index){
portfolio_index <- cbind(portfolio_index,
getSymbols.yahoo(Ticker, from="2010-01-01", periodicity = "weekly", auto.assign=FALSE)[,6])
}
colnames(portfolio_index) <- c("Stocks", "Bonds")
# Caluculating continuous returns
log_Returns<-diff(log(portfolio_index))[-1,]
# Defining risk free rate
risk_free_rate<-0
# a) Calculating the Sharpe-ratios for bonds and stocks
# I) Expected returns (see slide 32)
er_bonds <-
er_stocks <-
# II) Standard deviations (see slide 32)
sd_bonds <-
sd_stocks <-
# III) Sharpe-ratios for bonds and stocks
# Apply formula on slide 41, use the predefined objects er_bonds, er_stocks, sd_bonds, sd_stocks, and risk_free_rate
# b) Plotting efficient frontier
# Creating 1000 portfolio weights and calculating the corraltion between the two assets
x_weights <- seq(from = 0, to = 1, length.out = 1000)
cor_bs <-
# Creating a data.frame that contains the weights for the two asset and empty columns for the portfolio return, standard deviation and Sharpe-rations
pf <- data.frame(w_bonds = x_weights, w_stocks = 1 - x_weights, er_p=NA, sd_p=NA, sr_p=NA)
# Calculating the expected returns and standard deviations for the 1000 portfolios
for(i in 1:nrow(pf)){
pf$er_p[i]<- # Apply formula on slide 33 for each portfolio combination, use the predefined objects er_bonds and er_stocks
pf$sd_p[i]<- # Apply forumla on slide 34 for each portfolio combinaiton, use the predefined objects cor_bs sd_bonds and sd_stocks
}
# Plotting the efficient frontier
plot()
# c) Deriving the weightings of the market porftolio
## Identifying the market portfolio
# Calculating the Sharpe-ratio per portfolio (see slide 41)
pf$sr_p <- # Create the sr_p variable in the pf matrix using the er_p and sd_p variables of the same matrix
# Identifying the index of the market portfolio
indx_mp<- # Use which.max()
# c) Deriving the weightings of the market porftolio
## Identifying the market portfolio
# Calculating the Sharpe-ratio per portfolio (see slide 41)
pf$sr_p <- # Create the sr_p variable in the pf matrix using the er_p and sd_p variables of the same matrix
# Identifying the index of the market portfolio
indx_mp<- # Use which.max()
# c) Deriving the weightings of the market porftolio
## Identifying the market portfolio
# Calculating the Sharpe-ratio per portfolio (see slide 41)
pf$sr_p <- # Create the sr_p variable in the pf matrix using the er_p and sd_p variables of the same matrix
# Identifying the index of the market portfolio
indx_mp<- # Use which.max()
# c) Deriving the weightings of the market porftolio
## Identifying the market portfolio
# Calculating the Sharpe-ratio per portfolio (see slide 41)
pf$sr_p <- # Create the sr_p variable in the pf matrix using the er_p and sd_p variables of the same matrix
# Identifying the index of the market portfolio
indx_mp<- # Use which.max()
install.packages("tidyverse")
setwd("~/Git Repos/gcatt/App/app")
install.packages("tidyverse")
install.packages("tidyverse")
runApp()
getwd()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
install.packages("tidyverse")
### Zoom Video Communications
prices_zoom <- NULL
tickers_index <- c("ZM")
for (Ticker in tickers_index){
prices_zoom <- cbind(prices_zoom,
getSymbols.yahoo(Ticker, from="2020-01-01", periodicity = "daily",
auto.assign=FALSE)[,6])
}
prices_microsoft <- NULL
tickers_index <- c("MSFT")
for (Ticker in tickers_index){
prices_microsoft <- cbind(prices_microsoft,
getSymbols.yahoo(Ticker, from="2020-03-01", periodicity = "daily",
auto.assign=FALSE)[,6])
}
### Amazon
prices_amazon <- NULL
tickers_index <- c("AMZN")
for (Ticker in tickers_index){
prices_amazon <- cbind(prices_amazon,
getSymbols.yahoo(Ticker, from="2020-03-01", periodicity = "daily",
auto.assign=FALSE)[,6])
}
### JP Morgan Chase
prices_jpmorgan <- NULL
tickers_index <- c("JPM")
for (Ticker in tickers_index){
prices_jpmorgan <- cbind(prices_jpmorgan,
getSymbols.yahoo(Ticker, from="2020-03-01", periodicity = "daily",
auto.assign=FALSE)[,6])
}
### EXXON
prices_exxon <- NULL
tickers_index <- c("XOM")
for (Ticker in tickers_index){
prices_exxon <- cbind(prices,
getSymbols.yahoo(Ticker, from="2020-03-01", periodicity = "daily",
auto.assign=FALSE)[,6])
}
prices_slack <- NULL
tickers_index <- c("WORK")
for (Ticker in tickers_index){
prices_slack <- cbind(prices_slack,
getSymbols.yahoo(Ticker, from="2018-01-01", periodicity = "daily",
auto.assign=FALSE)[,6])
}
View(prices_exxon)
colnames(prices_slack)<-"Price"
colnames(prices_exxon)<-c("JPM","XOM")
colnames(prices_zoom)<-"ZM.Adjusted"
colnames(prices_amazon)<-"AMZN.Adjusted"
colnames(prices_microsoft)<-"MSFT.Adjusted"
colnames(prices_jpmorgan)<- "JPM.Adjusted"
plot_zoom <- ggplot()+
geom_line(data=prices_zoom, aes(x=Index, y=ZM.Adjusted, color="Zoom"), size=1.5)+
ylab("Stock price in $")+
xlab("Date")+
scale_colour_manual(name="Legend", values=c("red", "green", "blue", "yellow", "black", "violet"))
plot_zoom
plot_slack <- ggplot()+
geom_line(data=prices_slack, aes(x=Index, y= Price, color="Slack" ), size=1.5)+
ylab("Stock price in $")+
xlab("Date")+
scale_colour_manual(name="Legend", values=c("red", "green", "blue", "yellow", "black", "violet"))
plot_slack
install.packages("tidyverse")
runApp()
